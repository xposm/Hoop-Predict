{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Massey_2022_03_13.csv\n",
      "Shape of the filtered DataFrame for Massey_2022_03_13.csv: (358, 24)\n",
      "Processing Massey_2024_03_17.csv\n",
      "Shape of the filtered DataFrame for Massey_2024_03_17.csv: (362, 24)\n",
      "Processing Massey_2023_03_12.csv\n",
      "Shape of the filtered DataFrame for Massey_2023_03_12.csv: (363, 24)\n",
      "Processing Massey_2025_03_16.csv\n",
      "Shape of the filtered DataFrame for Massey_2025_03_16.csv: (364, 24)\n",
      "Processing Massey_2018_03_11.csv\n",
      "Shape of the filtered DataFrame for Massey_2018_03_11.csv: (351, 24)\n",
      "Processing Massey_2021_03_14.csv\n",
      "Shape of the filtered DataFrame for Massey_2021_03_14.csv: (347, 24)\n",
      "Processing Massey_2019_03_17.csv\n",
      "Shape of the filtered DataFrame for Massey_2019_03_17.csv: (353, 24)\n"
     ]
    }
   ],
   "source": [
    "PATH = r\"/Users/jimmyhe/Desktop/ML/KaggleCompetitions/NCAA/MasseyRating/\"\n",
    "OUTPUT_PATH = r'/Users/jimmyhe/Desktop/ML/KaggleCompetitions/NCAA/MasseyCleaned/'\n",
    "common_columns = None\n",
    "\n",
    "for filename in os.listdir(PATH):\n",
    "    if filename == '.DS_Store': \n",
    "        continue\n",
    "    filepath = os.path.join(PATH, filename)\n",
    "    \n",
    "    if os.path.isfile(filepath):\n",
    "        temp = pd.read_csv(filepath)\n",
    "        temp = temp.drop(temp.columns[[1, 2, 3, 4, 5]], axis=1)\n",
    "        \n",
    "        if common_columns is None:\n",
    "            common_columns = set(temp.columns)  # Initialize with columns of the first file\n",
    "        else:\n",
    "            common_columns &= set(temp.columns)  # Intersect with columns of subsequent files\n",
    "\n",
    "# Second pass: Process each file using the identified common columns\n",
    "for filename in os.listdir(PATH):\n",
    "    if filename == '.DS_Store': \n",
    "        continue\n",
    "    filepath = os.path.join(PATH, filename)\n",
    "    \n",
    "    if os.path.isfile(filepath):\n",
    "        print(f\"Processing {filename}\")\n",
    "        temp = pd.read_csv(filepath)        \n",
    "        df_filtered = temp[list(common_columns)].copy()\n",
    "        \n",
    "        # Optionally, add the 'Season' column to track the season\n",
    "        season_match = re.search(r\"_(\\d{4})_\", filepath)\n",
    "        if season_match:\n",
    "            season = season_match.group(1)\n",
    "            df_filtered['Season'] = int(season)\n",
    "        \n",
    "        print(f\"Shape of the filtered DataFrame for {filename}:\", df_filtered.shape)\n",
    "        \n",
    "        output_filename = f\"filtered_{filename}\" if season_match else f\"filtered_{filename}\"\n",
    "        df_filtered.to_csv(os.path.join(OUTPUT_PATH, output_filename), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Massey_2022_03_13.csv\n",
      "Shape of the filtered DataFrame for Massey_2022_03_13.csv: (358, 24)\n",
      "Processing Massey_2024_03_17.csv\n",
      "Shape of the filtered DataFrame for Massey_2024_03_17.csv: (362, 24)\n",
      "Processing Massey_2023_03_12.csv\n",
      "Shape of the filtered DataFrame for Massey_2023_03_12.csv: (363, 24)\n",
      "Processing Massey_2025_03_16.csv\n",
      "Shape of the filtered DataFrame for Massey_2025_03_16.csv: (364, 24)\n",
      "Processing Massey_2018_03_11.csv\n",
      "Shape of the filtered DataFrame for Massey_2018_03_11.csv: (351, 24)\n",
      "Processing Massey_2021_03_14.csv\n",
      "Shape of the filtered DataFrame for Massey_2021_03_14.csv: (347, 24)\n",
      "Processing Massey_2019_03_17.csv\n",
      "Shape of the filtered DataFrame for Massey_2019_03_17.csv: (353, 24)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "PATH = r\"/Users/jimmyhe/Desktop/ML/KaggleCompetitions/NCAA/MasseyRating/\"\n",
    "OUTPUT_PATH = r'/Users/jimmyhe/Desktop/ML/KaggleCompetitions/NCAA/MasseyCleaned/'\n",
    "\n",
    "common_columns = None\n",
    "\n",
    "# First pass: Identify common columns across all files\n",
    "for filename in os.listdir(PATH):\n",
    "    if filename == '.DS_Store': \n",
    "        continue\n",
    "    filepath = os.path.join(PATH, filename)\n",
    "    \n",
    "    if os.path.isfile(filepath):\n",
    "        temp = pd.read_csv(filepath)\n",
    "        temp = temp.drop(temp.columns[[1, 2, 3, 4, 5]], axis=1)\n",
    "        \n",
    "        if common_columns is None:\n",
    "            common_columns = set(temp.columns)  # Initialize with columns of the first file\n",
    "        else:\n",
    "            common_columns &= set(temp.columns)  # Intersect with columns of subsequent files\n",
    "\n",
    "# Second pass: Process each file using the identified common columns\n",
    "for filename in os.listdir(PATH):\n",
    "    if filename == '.DS_Store': \n",
    "        continue\n",
    "    filepath = os.path.join(PATH, filename)\n",
    "    \n",
    "    if os.path.isfile(filepath):\n",
    "        print(f\"Processing {filename}\")\n",
    "        temp = pd.read_csv(filepath)        \n",
    "        df_filtered = temp[list(common_columns)].copy()\n",
    "        \n",
    "        # Optionally, add the 'Season' column to track the season\n",
    "        season = None\n",
    "        season_match = re.search(r\"_(\\d{4})_\", filepath)\n",
    "        if season_match:\n",
    "            season = season_match.group(1)\n",
    "            df_filtered['Season'] = int(season)\n",
    "        \n",
    "        # Ensure \"Team\" and \"Season\" are the first columns in the filtered DataFrame\n",
    "        columns = ['Team', 'Season'] + [col for col in common_columns if col not in ['Team', 'Season']]\n",
    "        df_filtered = df_filtered[columns]\n",
    "        \n",
    "        # Debug: Print the shape of the filtered DataFrame\n",
    "        print(f\"Shape of the filtered DataFrame for {filename}: {df_filtered.shape}\")\n",
    "        \n",
    "        # Set output filename based on season presence\n",
    "        output_filename = f\"filtered_{filename}\"\n",
    "        \n",
    "        # Save the filtered DataFrame to the output path\n",
    "        df_filtered.to_csv(os.path.join(OUTPUT_PATH, output_filename), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /Users/jimmyhe/Desktop/ML/KaggleCompetitions/NCAA/MasseyCleaned/filtered_Massey_2021_03_14.csv\n",
      "Shape of filtered_Massey_2021_03_14.csv: (347, 24)\n",
      "Processing file: /Users/jimmyhe/Desktop/ML/KaggleCompetitions/NCAA/MasseyCleaned/filtered_Massey_2019_03_17.csv\n",
      "Shape of filtered_Massey_2019_03_17.csv: (353, 24)\n",
      "Processing file: /Users/jimmyhe/Desktop/ML/KaggleCompetitions/NCAA/MasseyCleaned/filtered_Massey_2018_03_11.csv\n",
      "Shape of filtered_Massey_2018_03_11.csv: (351, 24)\n",
      "Processing file: /Users/jimmyhe/Desktop/ML/KaggleCompetitions/NCAA/MasseyCleaned/filtered_Massey_2023_03_12.csv\n",
      "Shape of filtered_Massey_2023_03_12.csv: (363, 24)\n",
      "Processing file: /Users/jimmyhe/Desktop/ML/KaggleCompetitions/NCAA/MasseyCleaned/filtered_Massey_2025_03_16.csv\n",
      "Shape of filtered_Massey_2025_03_16.csv: (364, 24)\n",
      "Processing file: /Users/jimmyhe/Desktop/ML/KaggleCompetitions/NCAA/MasseyCleaned/filtered_Massey_2022_03_13.csv\n",
      "Shape of filtered_Massey_2022_03_13.csv: (358, 24)\n",
      "Processing file: /Users/jimmyhe/Desktop/ML/KaggleCompetitions/NCAA/MasseyCleaned/filtered_Massey_2024_03_17.csv\n",
      "Shape of filtered_Massey_2024_03_17.csv: (362, 24)\n",
      "Shape of the joined DataFrame: (2498, 24)\n",
      "Joined DataFrame saved to: /Users/jimmyhe/Desktop/ML/KaggleCompetitions/NCAA/MasseyCleaned/joined_Massey_Rating.csv\n",
      "Final shape: (2498, 24)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Cleaned_path = r\"/Users/jimmyhe/Desktop/ML/KaggleCompetitions/NCAA/MasseyCleaned/\"\n",
    "Massey_2025 = pd.read_csv(os.path.join(Cleaned_path, 'filtered_Massey_2025_03_16.csv'))\n",
    "reference_columns = Massey_2025.columns  # Use the columns from Massey_2025 as the reference\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(Cleaned_path):\n",
    "    raise FileNotFoundError(f\"The directory {Cleaned_path} does not exist.\")\n",
    "\n",
    "# List to store DataFrames for vertical concatenation\n",
    "dataframes = []\n",
    "\n",
    "# Iterate through files in the directory\n",
    "for filename in os.listdir(Cleaned_path):\n",
    "    if filename == '.DS_Store':  # Skip system files like .DS_Store on macOS\n",
    "        continue\n",
    "    filepath = os.path.join(Cleaned_path, filename)\n",
    "    \n",
    "    # Read each CSV file\n",
    "    print(f\"Processing file: {filepath}\")\n",
    "    temp = pd.read_csv(filepath)\n",
    "    print(f\"Shape of {filename}: {temp.shape}\")\n",
    "    \n",
    "    # Reorder columns to match the reference column order\n",
    "    temp = temp.reindex(columns=reference_columns)\n",
    "    \n",
    "    # Append the reordered DataFrame to the list\n",
    "    dataframes.append(temp)\n",
    "\n",
    "# Concatenate all DataFrames vertically (stacking rows)\n",
    "joined_df = pd.concat(dataframes, axis=0, ignore_index=True)  # `ignore_index=True` resets row indices\n",
    "\n",
    "print(f\"Shape of the joined DataFrame: {joined_df.shape}\")\n",
    "\n",
    "# Save the joined DataFrame to a new CSV file\n",
    "output_path = os.path.join(Cleaned_path, \"joined_Massey_Rating.csv\")\n",
    "joined_df.to_csv(output_path, index=False)\n",
    "print(f\"Joined DataFrame saved to: {output_path}\")\n",
    "print('Final shape:', joined_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2021, 2019, 2018, 2023, 2025, 2022, 2024])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df['Season'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2498, 24)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.rename(columns={'Team': 'TeamName'}, inplace=True)\n",
    "joined_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TeamID</th>\n",
       "      <th>TeamName</th>\n",
       "      <th>FirstD1Season</th>\n",
       "      <th>LastD1Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1101</td>\n",
       "      <td>Abilene Chr</td>\n",
       "      <td>2014</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1102</td>\n",
       "      <td>Air Force</td>\n",
       "      <td>1985</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1103</td>\n",
       "      <td>Akron</td>\n",
       "      <td>1985</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1104</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1985</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1105</td>\n",
       "      <td>Alabama A&amp;M</td>\n",
       "      <td>2000</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TeamID     TeamName  FirstD1Season  LastD1Season\n",
       "0    1101  Abilene Chr           2014          2025\n",
       "1    1102    Air Force           1985          2025\n",
       "2    1103        Akron           1985          2025\n",
       "3    1104      Alabama           1985          2025\n",
       "4    1105  Alabama A&M           2000          2025"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Comp_data_PATH = r\"/Users/jimmyhe/Desktop/ML/KaggleCompetitions/NCAA/march-machine-learning-mania-2025/\"\n",
    "M_teams = pd.read_csv(Comp_data_PATH + 'MTeams.csv')\n",
    "M_teams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TeamID</th>\n",
       "      <th>TeamName</th>\n",
       "      <th>FirstD1Season</th>\n",
       "      <th>LastD1Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1276</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>1985</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TeamID  TeamName  FirstD1Season  LastD1Season\n",
       "175    1276  Michigan           1985          2025"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_teams[M_teams[\"TeamName\"] == \"Michigan\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched TeamNames in the second DataFrame: {'Armstrong St', 'W Texas A&M', 'Brooklyn', 'NE Illinois', 'Alliant Intl', 'Centenary', 'Birmingham So', 'Hardin-Simmons', 'Morris Brown', 'Augusta', 'W Salem St', 'Okla City', 'Utica'}\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(joined_df, M_teams, on='TeamName', how='inner')\n",
    "\n",
    "# Check for unmatched TeamNames in df1\n",
    "unmatched_in_df1 = set(joined_df['TeamName']) - set(M_teams['TeamName'])\n",
    "if unmatched_in_df1:\n",
    "    raise ValueError(f\"Unmatched TeamNames in the first DataFrame: {unmatched_in_df1}\")\n",
    "\n",
    "# Check for unmatched TeamNames in df2\n",
    "unmatched_in_df2 = set(M_teams['TeamName']) - set(joined_df['TeamName'])\n",
    "if unmatched_in_df2:\n",
    "    print(f\"Unmatched TeamNames in the second DataFrame: {unmatched_in_df2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TeamNames_Massey:\n",
      "['Abilene Chr', 'Air Force', 'Akron', 'Alabama', 'Alabama A&M', 'Alabama St', 'Alcorn St', 'American Univ', 'Appalachian St', 'Arizona', 'Arizona St', 'Ark Little Rock', 'Ark Pine Bluff', 'Arkansas', 'Arkansas St', 'Army', 'Auburn', 'Austin Peay', 'BYU', 'Ball St', 'Baylor', 'Bellarmine', 'Belmont', 'Bethune-Cookman', 'Binghamton', 'Boise St', 'Boston College', 'Boston Univ', 'Bowling Green', 'Bradley', 'Brown', 'Bryant', 'Bucknell', 'Buffalo', 'Butler', 'C Michigan', 'CS Bakersfield', 'CS Fullerton', 'CS Northridge', 'CS Sacramento', 'Cal Baptist', 'Cal Poly', 'California', 'Campbell', 'Canisius', 'Cent Arkansas', 'Central Conn', 'Charleston So', 'Charlotte', 'Chattanooga', 'Chicago St', 'Cincinnati', 'Citadel', 'Clemson', 'Cleveland St', 'Coastal Car', 'Col Charleston', 'Colgate', 'Colorado', 'Colorado St', 'Columbia', 'Connecticut', 'Coppin St', 'Cornell', 'Creighton', 'Dartmouth', 'Davidson', 'Dayton', 'DePaul', 'Delaware', 'Delaware St', 'Denver', 'Detroit', 'Drake', 'Drexel', 'Duke', 'Duquesne', 'E Illinois', 'E Kentucky', 'E Michigan', 'E Washington', 'ETSU', 'East Carolina', 'East Texas A&M', 'Elon', 'Evansville', 'F Dickinson', 'FGCU', 'FL Atlantic', 'Fairfield', 'Florida', 'Florida A&M', 'Florida Intl', 'Florida St', 'Fordham', 'Fresno St', 'Furman', 'G Washington', 'Ga Southern', 'Gardner Webb', 'George Mason', 'Georgetown', 'Georgia', 'Georgia St', 'Georgia Tech', 'Gonzaga', 'Grambling', 'Grand Canyon', 'Hampton', 'Hartford', 'Harvard', 'Hawaii', 'High Point', 'Hofstra', 'Holy Cross', 'Houston', 'Houston Chr', 'Howard', 'IL Chicago', 'IUPUI', 'Idaho', 'Idaho St', 'Illinois', 'Illinois St', 'Incarnate Word', 'Indiana', 'Indiana St', 'Iona', 'Iowa', 'Iowa St', 'Jackson St', 'Jacksonville', 'Jacksonville St', 'James Madison', 'Kansas', 'Kansas St', 'Kennesaw', 'Kent', 'Kentucky', 'LIU Brooklyn', 'LSU', 'La Salle', 'Lafayette', 'Lamar', 'Le Moyne', 'Lehigh', 'Liberty', 'Lindenwood', 'Lipscomb', 'Long Beach St', 'Longwood', 'Louisiana', 'Louisiana Tech', 'Louisville', 'Loy Marymount', 'Loyola MD', 'Loyola-Chicago', 'MA Lowell', 'MD E Shore', 'MS Valley St', 'MTSU', 'Maine', 'Manhattan', 'Marist', 'Marquette', 'Marshall', 'Maryland', 'Massachusetts', 'McNeese St', 'Memphis', 'Mercer', 'Mercyhurst', 'Merrimack', 'Miami FL', 'Miami OH', 'Michigan', 'Michigan St', 'Minnesota', 'Mississippi', 'Mississippi St', 'Missouri', 'Missouri KC', 'Missouri St', 'Monmouth NJ', 'Montana', 'Montana St', 'Morehead St', 'Morgan St', \"Mt St Mary's\", 'Murray St', 'N Colorado', 'N Dakota St', 'N Illinois', 'N Kentucky', 'NC A&T', 'NC Central', 'NC State', 'NE Omaha', 'NJIT', 'Navy', 'Nebraska', 'Nevada', 'New Hampshire', 'New Mexico', 'New Mexico St', 'New Orleans', 'Niagara', 'Nicholls St', 'Norfolk St', 'North Alabama', 'North Carolina', 'North Dakota', 'North Florida', 'North Texas', 'Northeastern', 'Northern Arizona', 'Northern Iowa', 'Northwestern', 'Northwestern LA', 'Notre Dame', 'Oakland', 'Ohio', 'Ohio St', 'Oklahoma', 'Oklahoma St', 'Old Dominion', 'Oral Roberts', 'Oregon', 'Oregon St', 'PFW', 'Pacific', 'Penn', 'Penn St', 'Pepperdine', 'Pittsburgh', 'Portland', 'Portland St', 'Prairie View', 'Presbyterian', 'Princeton', 'Providence', 'Purdue', 'Queens NC', 'Quinnipiac', 'Radford', 'Rhode Island', 'Rice', 'Richmond', 'Rider', 'Robert Morris', 'Rutgers', 'S Carolina St', 'S Dakota St', 'S Illinois', 'SC Upstate', 'SE Louisiana', 'SE Missouri St', 'SF Austin', 'SIUE', 'SMU', 'SUNY Albany', 'Sacred Heart', 'Sam Houston St', 'Samford', 'San Diego', 'San Diego St', 'San Francisco', 'San Jose St', 'Santa Clara', 'Savannah St', 'Seattle', 'Seton Hall', 'Siena', 'South Alabama', 'South Carolina', 'South Dakota', 'South Florida', 'Southern Indiana', 'Southern Miss', 'Southern Univ', 'Southern Utah', 'St Bonaventure', 'St Francis NY', 'St Francis PA', \"St John's\", \"St Joseph's PA\", 'St Louis', \"St Mary's CA\", \"St Peter's\", 'St Thomas MN', 'Stanford', 'Stetson', 'Stonehill', 'Stony Brook', 'Syracuse', 'TAM C. Christi', 'TCU', 'TN Martin', 'TX Southern', 'Tarleton St', 'Temple', 'Tennessee', 'Tennessee St', 'Tennessee Tech', 'Texas', 'Texas A&M', 'Texas St', 'Texas Tech', 'Toledo', 'Towson', 'Troy', 'Tulane', 'Tulsa', 'UAB', 'UC Davis', 'UC Irvine', 'UC Riverside', 'UC San Diego', 'UC Santa Barbara', 'UCF', 'UCLA', 'ULM', 'UMBC', 'UNC Asheville', 'UNC Greensboro', 'UNC Wilmington', 'UNLV', 'USC', 'UT Arlington', 'UT San Antonio', 'UTEP', 'UTRGV', 'Utah', 'Utah St', 'Utah Tech', 'Utah Valley', 'VCU', 'VMI', 'Valparaiso', 'Vanderbilt', 'Vermont', 'Villanova', 'Virginia', 'Virginia Tech', 'W Carolina', 'W Illinois', 'W Michigan', 'WI Green Bay', 'WI Milwaukee', 'WKU', 'Wagner', 'Wake Forest', 'Washington', 'Washington St', 'Weber St', 'West Georgia', 'West Virginia', 'Wichita St', 'William & Mary', 'Winthrop', 'Wisconsin', 'Wofford', 'Wright St', 'Wyoming', 'Xavier', 'Yale', 'Youngstown St']\n",
      "\n",
      "TeamNames_Comp:\n",
      "['Abilene Chr', 'Air Force', 'Akron', 'Alabama', 'Alabama A&M', 'Alabama St', 'SUNY Albany', 'Alcorn St', 'Alliant Intl', 'American Univ', 'Appalachian St', 'Arizona', 'Arizona St', 'Ark Little Rock', 'Ark Pine Bluff', 'Arkansas', 'Arkansas St', 'Armstrong St', 'Army', 'Auburn', 'Augusta', 'Austin Peay', 'Ball St', 'Baylor', 'Belmont', 'Bethune-Cookman', 'Binghamton', 'Birmingham So', 'Boise St', 'Boston College', 'Boston Univ', 'Bowling Green', 'Bradley', 'Brooklyn', 'Brown', 'Bryant', 'Bucknell', 'Buffalo', 'Butler', 'BYU', 'C Michigan', 'Cal Poly', 'California', 'Campbell', 'Canisius', 'Cent Arkansas', 'Centenary', 'Central Conn', 'Charleston So', 'Charlotte', 'Chattanooga', 'Chicago St', 'Cincinnati', 'Citadel', 'Clemson', 'Cleveland St', 'Coastal Car', 'Col Charleston', 'Colgate', 'Colorado', 'Colorado St', 'Columbia', 'Connecticut', 'Coppin St', 'Cornell', 'Creighton', 'CS Bakersfield', 'CS Fullerton', 'CS Northridge', 'CS Sacramento', 'Dartmouth', 'Davidson', 'Dayton', 'Delaware', 'Delaware St', 'Denver', 'DePaul', 'Detroit', 'Drake', 'Drexel', 'Duke', 'Duquesne', 'E Illinois', 'E Kentucky', 'E Michigan', 'E Washington', 'East Carolina', 'SIUE', 'Elon', 'ETSU', 'Evansville', 'F Dickinson', 'Fairfield', 'FL Atlantic', 'FGCU', 'Florida', 'Florida A&M', 'Florida Intl', 'Florida St', 'Fordham', 'Fresno St', 'Furman', 'G Washington', 'Ga Southern', 'Gardner Webb', 'George Mason', 'Georgetown', 'Georgia', 'Georgia St', 'Georgia Tech', 'Gonzaga', 'Grambling', 'Grand Canyon', 'Hampton', 'Hardin-Simmons', 'Hartford', 'Harvard', 'Hawaii', 'High Point', 'Hofstra', 'Holy Cross', 'Houston', 'Houston Chr', 'Howard', 'Idaho', 'Idaho St', 'IL Chicago', 'Illinois', 'Illinois St', 'Incarnate Word', 'Indiana', 'Indiana St', 'Iona', 'Iowa', 'Iowa St', 'PFW', 'IUPUI', 'Jackson St', 'Jacksonville', 'Jacksonville St', 'James Madison', 'Kansas', 'Kansas St', 'Kennesaw', 'Kent', 'Kentucky', 'La Salle', 'Lafayette', 'Lamar', 'Lehigh', 'Liberty', 'Lipscomb', 'Long Beach St', 'LIU Brooklyn', 'Longwood', 'Louisiana Tech', 'Louisville', 'Loy Marymount', 'Loyola MD', 'Loyola-Chicago', 'LSU', 'MA Lowell', 'Maine', 'Manhattan', 'Marist', 'Marquette', 'Marshall', 'Maryland', 'Massachusetts', 'McNeese St', 'MD E Shore', 'Memphis', 'Mercer', 'Miami FL', 'Miami OH', 'Michigan', 'Michigan St', 'Minnesota', 'Mississippi', 'Mississippi St', 'Missouri', 'Missouri KC', 'Missouri St', 'Monmouth NJ', 'Montana', 'Montana St', 'Morehead St', 'Morgan St', 'Morris Brown', 'MS Valley St', \"Mt St Mary's\", 'MTSU', 'Murray St', 'N Colorado', 'N Dakota St', 'N Illinois', 'N Kentucky', 'Navy', 'NC A&T', 'NC Central', 'NC State', 'NE Illinois', 'NE Omaha', 'Nebraska', 'Nevada', 'New Hampshire', 'New Mexico', 'New Mexico St', 'New Orleans', 'Niagara', 'Nicholls St', 'NJIT', 'Norfolk St', 'North Carolina', 'North Dakota', 'North Florida', 'North Texas', 'Northeastern', 'Northern Arizona', 'Northern Iowa', 'Northwestern', 'Northwestern LA', 'Notre Dame', 'Oakland', 'Ohio', 'Ohio St', 'Okla City', 'Oklahoma', 'Oklahoma St', 'Old Dominion', 'Oral Roberts', 'Oregon', 'Oregon St', 'Pacific', 'Penn', 'Penn St', 'Pepperdine', 'Pittsburgh', 'Portland', 'Portland St', 'Prairie View', 'Presbyterian', 'Princeton', 'Providence', 'Purdue', 'Quinnipiac', 'Radford', 'Rhode Island', 'Rice', 'Richmond', 'Rider', 'Robert Morris', 'Rutgers', 'S Carolina St', 'S Dakota St', 'S Illinois', 'Sacred Heart', 'Sam Houston St', 'Samford', 'San Diego', 'San Diego St', 'San Francisco', 'San Jose St', 'UC Santa Barbara', 'Santa Clara', 'Savannah St', 'SC Upstate', 'SE Louisiana', 'SE Missouri St', 'Seattle', 'Seton Hall', 'SF Austin', 'Siena', 'SMU', 'South Alabama', 'South Carolina', 'South Dakota', 'South Florida', 'Southern Miss', 'Southern Univ', 'Southern Utah', 'St Bonaventure', 'St Francis NY', 'St Francis PA', \"St John's\", \"St Joseph's PA\", 'St Louis', \"St Mary's CA\", \"St Peter's\", 'Stanford', 'Stetson', 'Stony Brook', 'Syracuse', 'TAM C. Christi', 'TCU', 'Temple', 'Tennessee', 'Tennessee St', 'Tennessee Tech', 'Texas', 'Texas A&M', 'Texas St', 'Texas Tech', 'TN Martin', 'Toledo', 'Towson', 'Troy', 'Tulane', 'Tulsa', 'UTRGV', 'TX Southern', 'UAB', 'UC Davis', 'UC Irvine', 'UC Riverside', 'UCF', 'UCLA', 'Louisiana', 'ULM', 'UMBC', 'UNC Asheville', 'UNC Greensboro', 'UNC Wilmington', 'UNLV', 'USC', 'UT Arlington', 'UT San Antonio', 'Utah', 'Utah St', 'Utah Valley', 'UTEP', 'Utica', 'VCU', 'Valparaiso', 'Vanderbilt', 'Vermont', 'Villanova', 'Virginia', 'Virginia Tech', 'VMI', 'W Carolina', 'W Illinois', 'WKU', 'W Michigan', 'W Salem St', 'W Texas A&M', 'Wagner', 'Wake Forest', 'Washington', 'Washington St', 'Weber St', 'West Virginia', 'WI Green Bay', 'WI Milwaukee', 'Wichita St', 'William & Mary', 'Winthrop', 'Wisconsin', 'Wofford', 'Wright St', 'Wyoming', 'Xavier', 'Yale', 'Youngstown St', 'Cal Baptist', 'North Alabama', 'Merrimack', 'Bellarmine', 'Utah Tech', 'Tarleton St', 'UC San Diego', 'St Thomas MN', 'Lindenwood', 'Queens NC', 'Southern Indiana', 'Stonehill', 'East Texas A&M', 'Le Moyne', 'Mercyhurst', 'West Georgia']\n"
     ]
    }
   ],
   "source": [
    "TNames_Massey = joined_df['TeamName'].unique()\n",
    "TNames_Comp = M_teams['TeamName'].unique()\n",
    "TNames_Massey.sort()\n",
    "print(\"TeamNames_Massey:\")\n",
    "print(list(TNames_Massey))\n",
    "\n",
    "print(\"\\nTeamNames_Comp:\")\n",
    "print(list(TNames_Comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(367, 380)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(TNames_Massey), len(TNames_Comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_items = list(set(TNames_Massey) & set(TNames_Comp))\n",
    "len(common_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_in_sequence_one = list(set(TNames_Massey) - set(TNames_Comp))\n",
    "len(unique_in_sequence_one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Makes sure that the Massey Rating has the exact same format as teamanmes in the kaggle comp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TeamName</th>\n",
       "      <th>Season</th>\n",
       "      <th>POM</th>\n",
       "      <th>WIL</th>\n",
       "      <th>JNG</th>\n",
       "      <th>7OT</th>\n",
       "      <th>MAS</th>\n",
       "      <th>JJK</th>\n",
       "      <th>EBP</th>\n",
       "      <th>FAS</th>\n",
       "      <th>...</th>\n",
       "      <th>TRP</th>\n",
       "      <th>DII</th>\n",
       "      <th>MOR</th>\n",
       "      <th>TRK</th>\n",
       "      <th>KPK</th>\n",
       "      <th>RT</th>\n",
       "      <th>WLK</th>\n",
       "      <th>TeamID</th>\n",
       "      <th>FirstD1Season</th>\n",
       "      <th>LastD1Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gonzaga</td>\n",
       "      <td>2021</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1211</td>\n",
       "      <td>1985</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Baylor</td>\n",
       "      <td>2021</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1124</td>\n",
       "      <td>1985</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Illinois</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1228</td>\n",
       "      <td>1985</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Michigan</td>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1276</td>\n",
       "      <td>1985</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Houston</td>\n",
       "      <td>2021</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1222</td>\n",
       "      <td>1985</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TeamName  Season  POM  WIL  JNG 7OT  MAS JJK  EBP  FAS  ...  TRP  DII MOR  \\\n",
       "0   Gonzaga    2021    1    1    1   1    1   1    1    1  ...    1    1   1   \n",
       "1    Baylor    2021    4    2    2  19    3   2    2    2  ...    2    2   3   \n",
       "2  Illinois    2021    3    5    3  18    2   5    4    3  ...    3    3   2   \n",
       "3  Michigan    2021    2    4    4   9    4   3    6    4  ...    6    4   4   \n",
       "4   Houston    2021    6    9   12   4    6   4    3    5  ...    5    6   6   \n",
       "\n",
       "  TRK  KPK  RT  WLK  TeamID  FirstD1Season  LastD1Season  \n",
       "0   1    1   1    1    1211           1985          2025  \n",
       "1   3    2   3    3    1124           1985          2025  \n",
       "2   4    3   8    2    1228           1985          2025  \n",
       "3   5    4   5    4    1276           1985          2025  \n",
       "4   2    5   2    6    1222           1985          2025  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = joined_df.merge(M_teams, on='TeamName', how='left')\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = tmp[['TeamName','TeamID', 'Season', 'FirstD1Season',\n",
    "       'LastD1Season','POM', 'WIL', 'JNG', '7OT', 'MAS', 'JJK', 'EBP',\n",
    "       'FAS', 'HAS', 'DOK', 'LMC', 'USA', 'PGH', 'BBT', 'BIH', 'TRP', 'DII',\n",
    "       'MOR', 'TRK', 'KPK', 'RT', 'WLK',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train = final_train.sort_values(by='Season', ascending=False)\n",
    "final_train.to_csv('/Users/jimmyhe/Desktop/ML/KaggleCompetitions/NCAA/Train_Set/Massey_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NCAA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
